<!DOCTYPE html>
<html lang="zh">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Browser ASR (External)</title>
    <style>
        body {
            font-family: sans-serif;
            padding: 1em;
        }

        #status {
            margin-top: 1em;
            font-style: italic;
            color: #555;
        }

        #result {
            margin-top: 0.5em;
            border: 1px solid #ccc;
            padding: 0.5em;
            min-height: 50px;
            background: #f9f9f9;
        }
    </style>
</head>

<body>
    <h1>æµè§ˆå™¨è¯­éŸ³è¯†åˆ«ä¸­ç»§é¡µé¢</h1>
    <p>è¿™ä¸ªé¡µé¢éœ€è¦åœ¨æµè§ˆå™¨ä¸­ä¿æŒæ‰“å¼€ï¼Œä»¥ä¾¿åº”ç”¨ä½¿ç”¨å…¶è¯­éŸ³è¯†åˆ«åŠŸèƒ½ã€‚</p>
    <div id="status">æ­£åœ¨è¿æ¥åˆ°æœåŠ¡å™¨...</div>
    <div id="result"></div>

    <script>
        const statusDiv = document.getElementById('status');
        const resultDiv = document.getElementById('result');
        const ws = new WebSocket('ws://localhost:8080'); // Use the defined port
        let recognition = null;
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

        function updateStatus(message) {
            console.log(`[Browser Page Status] ${message}`);
            statusDiv.textContent = message;
        }

        ws.onopen = () => {
            updateStatus('å·²è¿æ¥åˆ°æœåŠ¡å™¨ï¼Œç­‰å¾…æŒ‡ä»¤...');
            ws.send(JSON.stringify({ type: 'identify', role: 'browser' }));
        };

        ws.onmessage = (event) => {
            let data;
            try {
                data = JSON.parse(event.data);
                console.log('[Browser Page] Received command:', data);
            } catch (e) {
                console.error('[Browser Page] Received non-JSON message:', event.data);
                return;
            }

            if (data.type === 'start') {
                startRecognition();
            } else if (data.type === 'stop') {
                stopRecognition();
            } else {
                console.warn('[Browser Page] Received unknown command type:', data.type);
            }
        };

        ws.onerror = (error) => {
            console.error('[Browser Page] WebSocket Error:', error);
            updateStatus('WebSocket è¿æ¥é”™è¯¯ï¼è¯·æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œã€‚');
        };

        ws.onclose = () => {
            console.log('[Browser Page] WebSocket Connection Closed');
            updateStatus('ä¸æœåŠ¡å™¨æ–­å¼€è¿æ¥ã€‚è¯·åˆ·æ–°é¡µé¢æˆ–é‡å¯æœåŠ¡å™¨ã€‚');
            stopRecognition();
        };

        function setupRecognition() {
            if (!SpeechRecognition) {
                updateStatus('é”™è¯¯ï¼šæ­¤æµè§ˆå™¨ä¸æ”¯æŒ Web Speech APIã€‚');
                return false;
            }
            if (recognition && recognition.recognizing) {
                console.log('[Browser Page] Recognition already active.');
                return true;
            }

            recognition = new SpeechRecognition();
            recognition.lang = 'zh-CN';
            recognition.continuous = true;
            recognition.interimResults = true;

            recognition.onstart = () => {
                updateStatus("ğŸ¤ æ­£åœ¨è¯†åˆ«...");
                console.log('[Browser Page] SpeechRecognition started.');
            };

            recognition.onresult = (event) => {
                let interim_transcript = '';
                let final_transcript = '';
                for (let i = event.resultIndex; i < event.results.length; ++i) {
                    if (event.results[i].isFinal) {
                        final_transcript += event.results[i][0].transcript;
                    } else {
                        interim_transcript += event.results[i][0].transcript;
                    }
                }
                const resultText = final_transcript || interim_transcript;
                resultDiv.textContent = resultText;

                if (ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: 'result', data: { text: resultText, isFinal: !!final_transcript } }));
                }
            };

            recognition.onerror = (event) => {
                console.error(`[Browser Page] SpeechRecognition Error - Type: ${event.error}, Message: ${event.message}`);
                updateStatus(`è¯†åˆ«é”™è¯¯: ${event.error}`);
                if (ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: 'error', data: { error: event.error, message: event.message || `Recognition error: ${event.error}` } }));
                }
            };

            recognition.onend = () => {
                console.log('[Browser Page] SpeechRecognition ended.');
                if (!statusDiv.textContent.includes('é”™è¯¯') && !statusDiv.textContent.includes('åœæ­¢')) {
                    updateStatus("è¯†åˆ«å·²åœæ­¢ã€‚ç­‰å¾…æŒ‡ä»¤...");
                }
                if (ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify({ type: 'status', message: 'stopped' }));
                }
                recognition = null;
            };
            return true;
        }

        function startRecognition() {
            if (!SpeechRecognition) {
                updateStatus('é”™è¯¯ï¼šæµè§ˆå™¨ä¸æ”¯æŒ Web Speech APIã€‚');
                return;
            }
            if (recognition) {
                console.log('[Browser Page] Recognition already exists, stopping first.');
                stopRecognition();
            }

            if (!setupRecognition()) return;

            console.log('[Browser Page] Attempting to start recognition...');
            try {
                navigator.mediaDevices.getUserMedia({ audio: true })
                    .then(stream => {
                        console.log('[Browser Page] Microphone access granted.');
                        stream.getTracks().forEach(track => track.stop());
                        if (recognition) {
                            recognition.start();
                        } else {
                            updateStatus('é”™è¯¯ï¼šRecognition å®ä¾‹ä¸¢å¤±ã€‚');
                            console.error('[Browser Page] Recognition instance lost before start.');
                        }
                    })
                    .catch(err => {
                        console.error('[Browser Page] Microphone access error:', err);
                        updateStatus(`é”™è¯¯: æ— æ³•è®¿é—®éº¦å…‹é£ (${err.name})`);
                        recognition = null;
                    });
            } catch (e) {
                console.error('[Browser Page] Error calling recognition.start():', e);
                updateStatus(`å¯åŠ¨è¯†åˆ«æ—¶å‡ºé”™: ${e.message}`);
                recognition = null;
            }
        }

        function stopRecognition() {
            if (recognition) {
                console.log('[Browser Page] Stopping recognition...');
                updateStatus("æ­£åœ¨åœæ­¢è¯†åˆ«...");
                try {
                    recognition.stop();
                } catch (e) {
                    console.error('[Browser Page] Error calling recognition.stop():', e);
                    recognition = null;
                    updateStatus("åœæ­¢æ—¶å‡ºé”™ï¼Œå·²å¼ºåˆ¶é‡ç½®ã€‚");
                }
            } else {
                console.log('[Browser Page] Recognition not active, nothing to stop.');
                updateStatus("è¯†åˆ«æœªè¿è¡Œã€‚");
            }
        }
    </script>
</body>

</html>