import {
  isReasoningModel,
  isSupportedReasoningEffortModel,
  isSupportedReasoningEffortOpenAIModel,
  isSupportedThinkingTokenModel,
  isSupportedThinkingTokenQwenModel
} from '@renderer/config/models'
import { getAssistantSettings, getDefaultModel } from '@renderer/services/AssistantService'
import {
  filterContextMessages,
  filterEmptyMessages,
  filterUserRoleStartMessages
} from '@renderer/services/MessagesService'
import { processPostsuffixQwen3Model, processReqMessages } from '@renderer/services/ModelMessageService'
import { addImageFileToContents } from '@renderer/utils/formats'
import { isEnabledToolUse } from '@renderer/utils/mcp-tools'
import { buildSystemPrompt } from '@renderer/utils/prompt'
import { takeRight } from 'lodash'
import { ChatCompletionMessageParam, ChatCompletionTool } from 'openai/resources'

import type { CompletionsParams } from '../../AiProvider'
import { AiProviderMiddlewareCompletionsContext, CompletionsMiddleware } from '../middlewareTypes'

const MIDDLEWARE_NAME = 'TransformParamsBeforeCompletions'

/**
 * å‚æ•°è½¬æ¢ä¸­é—´ä»¶
 * è´Ÿè´£å°† CompletionsParams è½¬æ¢ä¸ºæ ‡å‡†åŒ–çš„æ ¼å¼ï¼Œæå– completions å‡½æ•°ä¸­çš„å‚æ•°å¤„ç†é€»è¾‘
 */
export const TransformParamsBeforeCompletions: CompletionsMiddleware =
  () => (next) => async (context: AiProviderMiddlewareCompletionsContext, params: CompletionsParams) => {
    console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Starting parameter transformation`)

    try {
      // æ£€æŸ¥å‚æ•°æ˜¯å¦å·²ç»åŒ…å«è½¬æ¢åçš„æ•°æ®ï¼ˆé€’å½’è°ƒç”¨æ—¶é¿å…é‡å¤è½¬æ¢ï¼‰
      if (params._internal?.sdkParams) {
        console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Parameters already transformed, skipping transformation`)
        return next(context, params)
      }

      // è·å– provider å®ä¾‹
      const provider = context._providerInstance
      if (!provider) {
        throw new Error('Provider instance not found in context')
      }

      // 1. åŸºç¡€å‚æ•°å¤„ç†
      const defaultModel = getDefaultModel()
      const model = params.assistant.model || defaultModel
      const { contextCount, maxTokens, streamOutput } = getAssistantSettings(params.assistant)

      // 2. æ¶ˆæ¯é¢„å¤„ç† - å®Œæ•´å®ç°
      const processedMessages = addImageFileToContents(params.messages)

      // 3. æ¨ç†æ¨¡å¼æ£€æµ‹ - å®Œæ•´å®ç°
      const enableReasoning =
        ((isSupportedThinkingTokenModel(model) || isSupportedReasoningEffortModel(model)) &&
          params.assistant.settings?.reasoning_effort !== undefined) ||
        (isReasoningModel(model) && (!isSupportedThinkingTokenModel(model) || !isSupportedReasoningEffortModel(model)))

      // 4. ç³»ç»Ÿæ¶ˆæ¯æ„å»º - å®Œæ•´å®ç°
      let systemMessage = { role: 'system', content: params.assistant.prompt || '' }

      if (isSupportedReasoningEffortOpenAIModel(model)) {
        systemMessage = {
          role: 'developer',
          content: `Formatting re-enabled${systemMessage ? '\n' + systemMessage.content : ''}`
        }
      }

      if (model.id.includes('o1-preview') || model.id.includes('o1-mini')) {
        systemMessage = {
          role: 'assistant',
          content: `Formatting re-enabled${systemMessage ? '\n' + systemMessage.content : ''}`
        }
      }

      // 5. å·¥å…·é…ç½® - å®Œæ•´å®ç°
      const { tools } = provider.setupToolsConfig<ChatCompletionTool>({
        mcpTools: params.mcpTools,
        model,
        enableToolUse: isEnabledToolUse(params.assistant)
      })

      // 6. ç³»ç»Ÿæç¤ºè¯å·¥å…·å¢å¼º - å®Œæ•´å®ç°
      if (provider.useSystemPromptForTools) {
        systemMessage.content = buildSystemPrompt(systemMessage.content || '', params.mcpTools)
      }

      // 7. ç”¨æˆ·æ¶ˆæ¯å¤„ç† - å®Œæ•´å®ç°
      const userMessages: ChatCompletionMessageParam[] = []
      const _messages = filterUserRoleStartMessages(
        filterEmptyMessages(filterContextMessages(takeRight(processedMessages, contextCount + 1)))
      )

      // è°ƒç”¨æ¶ˆæ¯è¿‡æ»¤å›è°ƒ
      params.onFilterMessages?.(_messages)

      // è½¬æ¢æ¶ˆæ¯æ ¼å¼
      for (const message of _messages) {
        userMessages.push(await provider.getMessageParam(message, model))
      }

      // 8. ç‰¹æ®Šæ¨¡å‹å¤„ç†ï¼ˆQwenæ€è€ƒæ¨¡å¼ï¼‰- å®Œæ•´å®ç°
      const lastUserMsg = userMessages.findLast((m) => m.role === 'user')
      if (lastUserMsg && isSupportedThinkingTokenQwenModel(model)) {
        const postsuffix = '/no_think'
        const qwenThinkModeEnabled = params.assistant.settings?.qwenThinkMode === true
        const currentContent = lastUserMsg.content

        lastUserMsg.content = processPostsuffixQwen3Model(currentContent, postsuffix, qwenThinkModeEnabled) as any
      }

      // 9. æ„å»ºè¯·æ±‚æ¶ˆæ¯æ•°ç»„
      let reqMessages: ChatCompletionMessageParam[]
      if (!systemMessage.content) {
        reqMessages = [...userMessages]
      } else {
        reqMessages = [systemMessage, ...userMessages].filter(Boolean) as ChatCompletionMessageParam[]
      }

      // 10. æ¶ˆæ¯åå¤„ç† - å®Œæ•´å®ç°
      reqMessages = processReqMessages(model, reqMessages)

      // å°†è½¬æ¢åçš„å‚æ•°é™„åŠ åˆ° params çš„ _internal å­—æ®µä¸­

      const _internal = {
        // SDKæ¥å£éœ€è¦çš„å‚æ•°
        sdkParams: {
          reqMessages,
          tools,
          systemMessage,
          model,
          maxTokens,
          streamOutput
        },
        // å†…éƒ¨å¤„ç†å¯èƒ½ä¼šéœ€è¦çš„å‚æ•°
        enableReasoning,
        userMessages,
        contextCount,
        processedMessages: _messages
      }
      params._internal = _internal

      console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Parameter transformation completed`)
      console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Model: ${model.id}`)
      console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Messages count: ${reqMessages.length}`)
      console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Tools count: ${tools?.length || 0}`)
      console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Max tokens: ${maxTokens}`)
      console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Stream output: ${streamOutput}`)
      console.log(`ğŸ”„ [${MIDDLEWARE_NAME}] Enable reasoning: ${enableReasoning}`)

      return next(context, params)
    } catch (error) {
      console.error(`ğŸ”„ [${MIDDLEWARE_NAME}] Error during parameter transformation:`, error)
      throw error
    }
  }

export default TransformParamsBeforeCompletions
